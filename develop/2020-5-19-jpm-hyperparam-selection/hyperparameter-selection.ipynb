{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-19T17:14:48.436642Z",
     "iopub.status.busy": "2020-05-19T17:14:48.436136Z",
     "iopub.status.idle": "2020-05-19T17:14:48.450410Z",
     "shell.execute_reply": "2020-05-19T17:14:48.447508Z",
     "shell.execute_reply.started": "2020-05-19T17:14:48.436594Z"
    }
   },
   "source": [
    "# Thoughts on Hyperparameter selection/storary.\n",
    "\n",
    "Analysis by Jeremy P Mann\n",
    "\n",
    "Main goal of this notebook is to nail down the hyperparameters for the basic ML pipeline I outlined previously. This will be stored as YAML file alongside this notebook. No training will be done at this point. This notebook was mainly just me getting the hang of storing/loading yaml files. \n",
    "\n",
    "These models will be: \n",
    "\n",
    "- Logistic Regression \n",
    "- Rbf SVC \n",
    "- XGBoost \n",
    "- Random Forest\n",
    "\n",
    "I chose hyperparameters in a really ad hoc way, mainly by looking at people's choices in other competitions. This brings up some subtle points that I don't really understand:\n",
    "\n",
    "- Although obviously there's no \"best\" initial choice of hyperparameters, one shouldn't be reinventing the wheel when doing *preliminary*, \"benchmark\" ML experiments. There should be some *convention* for model choices/hyperparameters for every fixed type of learning problem. \n",
    "    - Although sklearn's \"default\" choices are the obvious choice, they change and therefore lack reproducibility. The software part of the reproducibility can be fixed with requirements.txt files, but this doesn't address the human part of the equation. \n",
    "    - The goal of this would not be to get a really good model, but to just set a context for the nature and difficulty of the learning problem that is established by convention. \n",
    "        - I can't emphasize the *convention* part! \n",
    "    - An simple use case would be to say with confidence that, for example, some 'expensive' ML algorithm gives *statistcally significant* improvements over more conventional methods.\n",
    "    - The analysis should be extremely automated and thorough.\n",
    "\n",
    "For concreteness, I will restrict myself to classification problems, where the features have been engineered (e.g. the \"trivial\" engineering where the features are given by the raw data)\n",
    "The analysis should give:\n",
    "- breakdowns of the distribution of features amongst each class. \n",
    "- Distributions of confusion matrices, and summary statistics of these distributions\n",
    "- Precision/sensitivy/accuracy broken down by classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-21T15:18:42.920371Z",
     "iopub.status.busy": "2020-05-21T15:18:42.919032Z",
     "iopub.status.idle": "2020-05-21T15:18:45.332349Z",
     "shell.execute_reply": "2020-05-21T15:18:45.331337Z",
     "shell.execute_reply.started": "2020-05-21T15:18:42.920240Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-21T15:19:43.364610Z",
     "iopub.status.busy": "2020-05-21T15:19:43.364308Z",
     "iopub.status.idle": "2020-05-21T15:19:43.389202Z",
     "shell.execute_reply": "2020-05-21T15:19:43.387195Z",
     "shell.execute_reply.started": "2020-05-21T15:19:43.364579Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"sample_hyperparameters.yml\", \"r\") as ymlfile:\n",
    "    params = yaml.safe_load(ymlfile)\n",
    "\n",
    "params\n",
    "model_names = params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-05-21T15:19:44.468428Z",
     "iopub.status.busy": "2020-05-21T15:19:44.467840Z",
     "iopub.status.idle": "2020-05-21T15:19:44.488834Z",
     "shell.execute_reply": "2020-05-21T15:19:44.483174Z",
     "shell.execute_reply.started": "2020-05-21T15:19:44.468371Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'stored_file.yaml', 'w') as file:\n",
    "    documents = yaml.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
